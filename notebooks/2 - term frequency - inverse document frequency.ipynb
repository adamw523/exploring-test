{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "https://en.wikipedia.org/wiki/Tf%E2%80%93idf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import gzip, pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "corpus = [\n",
    "    \"The sun is warm, warm, warm!\",\n",
    "    \"The coldest winters last forever\",\n",
    "    \"Cooling off in the pool is nice\",\n",
    "    \"Summer is warmer than winter. It is the warmest.\",\n",
    "    \"The coldest beer is the best beer\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Term Frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Tokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<5x21 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 29 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "tf = vectorizer.fit_transform(corpus)\n",
    "tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of features: 21\n",
      "['beer', 'best', 'coldest', 'cooling', 'forever', 'in', 'is', 'it', 'last', 'nice', 'off', 'pool', 'summer', 'sun', 'than', 'the', 'warm', 'warmer', 'warmest', 'winter', 'winters']\n"
     ]
    }
   ],
   "source": [
    "print('number of features:', len(vectorizer.get_feature_names()))\n",
    "print(vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 3, 0, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 2, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0],\n",
       "       [2, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<5x14 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 15 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "tf = vectorizer.fit_transform(corpus)\n",
    "tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of features: 14\n",
      "['beer', 'best', 'coldest', 'cooling', 'forever', 'nice', 'pool', 'summer', 'sun', 'warm', 'warmer', 'warmest', 'winter', 'winters']\n"
     ]
    }
   ],
   "source": [
    "print('number of features:', len(vectorizer.get_feature_names()))\n",
    "print(vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 1, 3, 0, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0],\n",
       "       [2, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "stem_words = ['warm', 'warmer', 'warmest', 'warming', 'warmed', 'lying', 'lied', 'fairly']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem.lancaster import LancasterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['warm', 'warmer', 'warmest', 'warm', 'warm', 'lie', 'lie', 'fair']"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer = SnowballStemmer('english')\n",
    "list(map(stemmer.stem, stem_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['warm', 'warmer', 'warmest', 'warm', 'warm', 'lie', 'lie', 'fairli']"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer = PorterStemmer()\n",
    "list(map(stemmer.stem, stem_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['warm', 'warm', 'warmest', 'warm', 'warm', 'lying', 'lied', 'fair']"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer = LancasterStemmer()\n",
    "list(map(stemmer.stem, stem_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['warm', 'warm', 'warmest', 'warm', 'warm', 'lie', 'lie', 'fair']"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ss = SnowballStemmer('english')\n",
    "ls = LancasterStemmer()\n",
    "\n",
    "list(map(ls.stem, map(ss.stem, stem_words)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Vectorize with stemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "default_tokenizer = CountVectorizer().build_tokenizer()\n",
    "\n",
    "def stemmed_tokenizer(doc):\n",
    "    tokens = default_tokenizer(doc)\n",
    "    return list(map(ls.stem, map(ss.stem, tokens)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<5x12 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 15 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(stop_words='english', tokenizer=stemmed_tokenizer)\n",
    "tf = vectorizer.fit_transform(corpus)\n",
    "tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of features: 12\n",
      "['beer', 'best', 'coldest', 'cool', 'forev', 'nic', 'pool', 'sum', 'sun', 'warm', 'warmest', 'wint']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 1, 3, 0, 0],\n",
       "       [0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1],\n",
       "       [2, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('number of features:', len(vectorizer.get_feature_names()))\n",
    "print(vectorizer.get_feature_names())\n",
    "tf.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Similarity between documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        ,  0.        ,  0.        ,  0.47434165,  0.        ],\n",
       "       [ 0.        ,  1.        ,  0.        ,  0.28867513,  0.23570226],\n",
       "       [ 0.        ,  0.        ,  1.        ,  0.        ,  0.        ],\n",
       "       [ 0.47434165,  0.28867513,  0.        ,  1.        ,  0.        ],\n",
       "       [ 0.        ,  0.23570226,  0.        ,  0.        ,  1.        ]])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarities = cosine_similarity(tf)\n",
    "similarities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Plot the similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.5/site-packages/matplotlib/font_manager.py:1297: UserWarning: findfont: Font family ['sans-serif'] not found. Falling back to DejaVu Sans\n",
      "  (prop.get_family(), self.defaultFamily[fontext]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 The sun is warm, warm, warm!\n",
      "1 The coldest winters last forever\n",
      "2 Cooling off in the pool is nice\n",
      "3 Summer is warmer than winter. It is the warmest.\n",
      "4 The coldest beer is the best beer\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQYAAADMCAYAAACRMQ1aAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niYGIdP4P+ueuVOsimeUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8bcb9a5748>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#http://seaborn.pydata.org/examples/network_correlations.html?highlight=correlation\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set up the matplotlib figure\n",
    "f, ax = plt.subplots(figsize=(6, 3))\n",
    "\n",
    "# Draw the heatmap using seaborn\n",
    "sns.heatmap(similarities, vmax=.8, square=True)\n",
    "\n",
    "f.tight_layout()\n",
    "\n",
    "for i, v in enumerate(corpus):\n",
    "    print(i, v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Similarity to test document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['beer',\n",
       " 'best',\n",
       " 'coldest',\n",
       " 'cool',\n",
       " 'forev',\n",
       " 'nic',\n",
       " 'pool',\n",
       " 'sum',\n",
       " 'sun',\n",
       " 'warm',\n",
       " 'warmest',\n",
       " 'wint']"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = vectorizer.get_feature_names()\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_doc = \"I like sun and beer by the pool\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_doc_vector = vectorizer.transform([test_doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0]])"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_doc_vector.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features_ixs = list(test_doc_vector.nonzero()[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Features common training set and test document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['beer', 'pool', 'sun']"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[features[ix] for ix in features_ixs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.18257419  0.          0.33333333  0.          0.47140452]\n"
     ]
    }
   ],
   "source": [
    "sims = cosine_similarity(test_doc_vector, tf)[0]\n",
    "print(sims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ordered_ixs = np.argsort(sims)[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 2 0 3 1]\n"
     ]
    }
   ],
   "source": [
    "print(ordered_ixs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.471404520791 \t The coldest beer is the best beer\n",
      "0.333333333333 \t Cooling off in the pool is nice\n",
      "0.182574185835 \t The sun is warm, warm, warm!\n",
      "0.0 \t Summer is warmer than winter. It is the warmest.\n",
      "0.0 \t The coldest winters last forever\n"
     ]
    }
   ],
   "source": [
    "for ix in ordered_ixs:\n",
    "    print(sims[ix], '\\t', corpus[ix])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Movie Quotes Term Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "      <th>imdb_rating</th>\n",
       "      <th>no_imdb_votes</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movieID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>m616</th>\n",
       "      <td>zulu dawn</td>\n",
       "      <td>1979</td>\n",
       "      <td>6.4</td>\n",
       "      <td>1911</td>\n",
       "      <td>['action', 'adventure', 'drama', 'history', 'w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>characterID</th>\n",
       "      <th>character_name</th>\n",
       "      <th>movie_title</th>\n",
       "      <th>gender</th>\n",
       "      <th>credits_position</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movieID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>m616</th>\n",
       "      <td>u9034</td>\n",
       "      <td>VEREKER</td>\n",
       "      <td>zulu dawn</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>characterID</th>\n",
       "      <th>movieID</th>\n",
       "      <th>character_ame</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lineID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>L666256</th>\n",
       "      <td>u9034</td>\n",
       "      <td>m616</td>\n",
       "      <td>VEREKER</td>\n",
       "      <td>Colonel Durnford... William Vereker. I hear yo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>firstCharacterID</th>\n",
       "      <th>secondCharacterID</th>\n",
       "      <th>movieId</th>\n",
       "      <th>order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>83096</th>\n",
       "      <td>u9030</td>\n",
       "      <td>u9034</td>\n",
       "      <td>m616</td>\n",
       "      <td>['L666520', 'L666521', 'L666522']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def read_file(name):\n",
    "    contents = None\n",
    "    with gzip.open(name) as f:\n",
    "        contents = pickle.load(f)\n",
    "    return contents\n",
    "\n",
    "movies_df = read_file('df_movies.pkl.gz')\n",
    "characters_df = read_file('df_characters.pkl.gz')\n",
    "lines_df = read_file('df_lines.pkl.gz')\n",
    "conversations_df = read_file('df_conversations.pkl.gz')\n",
    "\n",
    "HTML(movies_df.tail(1).to_html() + \\\n",
    "    characters_df.tail(1).to_html() + \\\n",
    "    lines_df.tail(1).to_html() + \\\n",
    "    conversations_df.tail(1).to_html())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'They do not!'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = np.array(lines_df['text'])\n",
    "lines[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Document-Term Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def lines_tokenizer(doc):\n",
    "    tokens = default_tokenizer(doc)\n",
    "    return list(map(ss.stem, tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "mvectorizer = CountVectorizer(stop_words='english', tokenizer=lines_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 42.8 s, sys: 0 ns, total: 42.8 s\n",
      "Wall time: 42.8 s\n"
     ]
    }
   ],
   "source": [
    "%time mtf = mvectorizer.fit_transform(lines_df['text'])\n",
    "mfeatures = mvectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(304713, 33620)\n"
     ]
    }
   ],
   "source": [
    "# (samples, features)\n",
    "print(mtf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['nonstop' 'vulgar' 'vortex' 'nasi' 'mclullen' 'rocki' 'hooaaa'\n",
      " 'waterfront' 'puddlevill' 'lug']\n"
     ]
    }
   ],
   "source": [
    "print(np.random.choice(mfeatures, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "characterID                                                    u27\n",
      "movieID                                                         m2\n",
      "character_ame                                               DAPHNE\n",
      "text             I'm sorry.  I didn't mean to...I'm glad. Actua...\n",
      "Name: L3181, dtype: object\n",
      "\n",
      "I'm sorry.  I didn't mean to...I'm glad. Actually I'm glad it's over.  All this time.  Hiding.  Never being able to look anyone in the eyes. Always afraid that someone would find out who I was.  Never trusting anyone...\n"
     ]
    }
   ],
   "source": [
    "line_ix = 1012\n",
    "print(lines_df.iloc[line_ix])\n",
    "print()\n",
    "print(lines_df.iloc[line_ix]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 hide\n",
      "2 glad\n",
      "1 abl\n",
      "1 eye\n",
      "1 afraid\n",
      "2 anyon\n",
      "1 sorri\n",
      "1 time\n",
      "1 trust\n",
      "1 mean\n",
      "1 actual\n",
      "1 didn\n",
      "1 someon\n",
      "1 alway\n",
      "1 look\n"
     ]
    }
   ],
   "source": [
    "tv = mtf[line_ix]\n",
    "for ix in tv.indices:\n",
    "    print(tv.toarray()[0][ix], mfeatures[ix])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Compare with a new string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['how', 'do', 'you', 'predict', 'what', 'will', 'be', 'said']\n"
     ]
    }
   ],
   "source": [
    "mtest_string = \"how do you predict what will be said\"\n",
    "tokens = mvectorizer.tokenizer(mtest_string)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Transform to a vector\n",
    "\n",
    "Transform to a vector that matches up to the vectors we have in our training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x33620 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 2 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mtest_vector = mvectorizer.transform([mtest_string])\n",
    "mtest_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mfeatures = mvectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33620"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mfeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict\n",
      "said\n"
     ]
    }
   ],
   "source": [
    "for ix in mtest_vector.nonzero()[1]:\n",
    "    print(mfeatures[ix])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 41.7 ms, sys: 12.1 ms, total: 53.8 ms\n",
      "Wall time: 52.6 ms\n"
     ]
    }
   ],
   "source": [
    "%time msims = cosine_similarity(mtest_vector, tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.70710678118654746"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(sims[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "mordered_ixs = np.argsort(msims[0])[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You said there were none.\n",
      "I said out.  Now.\n",
      "But you said --\n",
      "I said no.\n",
      "That's what I said.\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(lines_df.iloc[mordered_ixs[i]]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Inverse Document Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "test_vectorizer = TfidfVectorizer(stop_words='english', tokenizer=stemmed_tokenizer)\n",
    "test_idf = test_vectorizer.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The coldest winters last forever\n",
      "['beer', 'best', 'coldest', 'cool', 'forev', 'nic', 'pool', 'sum', 'sun', 'warm', 'warmest', 'wint']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.        ,  0.        ,  0.53177225,  0.        ,  0.659118  ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.53177225])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(corpus[1])\n",
    "print(test_vectorizer.get_feature_names())\n",
    "test_idf.toarray()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### IDF on Movie Quotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "idf_vectorizer = TfidfVectorizer(stop_words='english', tokenizer=lines_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 43 s, sys: 4.3 ms, total: 43 s\n",
      "Wall time: 43 s\n"
     ]
    }
   ],
   "source": [
    "%time idf_tf = idf_vectorizer.fit_transform(lines_df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "idf_test_string = test_string\n",
    "idf_tokens = idf_vectorizer.tokenizer(idf_test_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x33620 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 2 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idf_test_vector = idf_vectorizer.transform([idf_test_string])\n",
    "idf_test_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 60.4 ms, sys: 1 Âµs, total: 60.4 ms\n",
      "Wall time: 59.4 ms\n"
     ]
    }
   ],
   "source": [
    "%time idf_sims = cosine_similarity(idf_test_vector, idf_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "idf_ordered_ixs = np.argsort(idf_sims[0])[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I predicted it.\n",
      "You're so predictable.\n",
      "You're so predictable.\n",
      "Right.  You predicted it.\n",
      "I was gonna predict that.\n"
     ]
    }
   ],
   "source": [
    "# Top 5 matches\n",
    "for i in range(5):\n",
    "    print(lines_df.iloc[idf_ordered_ixs[i]]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Compare vectorizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "simple_vectorizer = CountVectorizer()\n",
    "simple_tf = simple_vectorizer.fit_transform(lines_df['text'])\n",
    "\n",
    "simple_stemmed_vectorizer = CountVectorizer(tokenizer=lines_tokenizer)\n",
    "simple_stemmed_tf = simple_stemmed_vectorizer.fit_transform(lines_df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "simple_idf_vectorizer = TfidfVectorizer()\n",
    "simple_idf_tf = simple_idf_vectorizer.fit_transform(lines_df['text'])\n",
    "\n",
    "simple_idf_stemmed_vectorizer = TfidfVectorizer(tokenizer=lines_tokenizer)\n",
    "simple_idf_stemmed_tf = simple_idf_stemmed_vectorizer.fit_transform(lines_df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.feature_extraction.text.CountVectorizer'> \n",
      " None \n",
      " None\n",
      "\n",
      "<class 'sklearn.feature_extraction.text.CountVectorizer'> \n",
      " None \n",
      " <function lines_tokenizer at 0x7f8bcdd6ed90>\n",
      "\n",
      "<class 'sklearn.feature_extraction.text.CountVectorizer'> \n",
      " english \n",
      " <function lines_tokenizer at 0x7f8bcdd6ed90>\n",
      "\n",
      "<class 'sklearn.feature_extraction.text.TfidfVectorizer'> \n",
      " None \n",
      " None\n",
      "\n",
      "<class 'sklearn.feature_extraction.text.TfidfVectorizer'> \n",
      " None \n",
      " <function lines_tokenizer at 0x7f8bcdd6ed90>\n",
      "\n",
      "<class 'sklearn.feature_extraction.text.TfidfVectorizer'> \n",
      " english \n",
      " <function lines_tokenizer at 0x7f8bcdd6ed90>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def print_deets(vec):\n",
    "    print(type(vec), '\\n', vec.stop_words, '\\n', vec.tokenizer)\n",
    "    print()\n",
    "\n",
    "print_deets(simple_vectorizer)\n",
    "print_deets(simple_stemmed_vectorizer)\n",
    "print_deets(vectorizer)\n",
    "\n",
    "print_deets(simple_idf_vectorizer)\n",
    "print_deets(simple_idf_stemmed_vectorizer)\n",
    "print_deets(idf_vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_matches(vectorizer, tf, count, doc):\n",
    "    vector = vectorizer.transform([doc])\n",
    "    \n",
    "    sims = cosine_similarity(vector, tf)\n",
    "    ordered_ixs = np.argsort(sims[0])[::-1]\n",
    "    \n",
    "    return [lines_df.iloc[ordered_ixs[i]] for i in range(count)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stopwords: None , tokenizer: None\n",
      "----------\n",
      "Thank you. For everything.  Beam me up, Scotty.\n",
      "Zip me up?\n",
      "\n",
      "stopwords: None , tokenizer: <function lines_tokenizer at 0x7f8bcdd6ed90>\n",
      "----------\n",
      "Thank you. For everything.  Beam me up, Scotty.\n",
      "Pick me up?\n",
      "\n",
      "stopwords: english , tokenizer: <function lines_tokenizer at 0x7f8bcdd6ed90>\n",
      "----------\n",
      "Scottie, Scottie...\n",
      "Scotty!\n",
      "\n",
      "stopwords: None , tokenizer: None\n",
      "----------\n",
      "Thank you. For everything.  Beam me up, Scotty.\n",
      "Scotty?\n",
      "\n",
      "stopwords: None , tokenizer: <function lines_tokenizer at 0x7f8bcdd6ed90>\n",
      "----------\n",
      "Thank you. For everything.  Beam me up, Scotty.\n",
      "Scotty!\n",
      "\n",
      "stopwords: english , tokenizer: <function lines_tokenizer at 0x7f8bcdd6ed90>\n",
      "----------\n",
      "Thank you. For everything.  Beam me up, Scotty.\n",
      "I really did think I was still in reality. At least, until now.  Beam me up, Scotty!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "compare_string = \"beam me up scotty\"\n",
    "#compare_string = \"What is your favourite place in the world?\"\n",
    "#compare_string = \"Chewie, we're home.\"\n",
    "#compare_string = \"Magic Mirror on the wall, who is the fairest one of all?\"\n",
    "#compare_string = \"Just when I thought I was out, they pull me back in.\"\n",
    "#compare_string = \"Fasten your seatbelts. It's going to be a bumpy night.\"\n",
    "\n",
    "\n",
    "test_vecs = [\n",
    "    [simple_vectorizer, simple_tf],\n",
    "    [simple_stemmed_vectorizer, simple_stemmed_tf],\n",
    "    [vectorizer, tf],\n",
    "    [simple_idf_vectorizer, simple_idf_tf],\n",
    "    [simple_idf_stemmed_vectorizer, simple_idf_stemmed_tf],\n",
    "    [idf_vectorizer, idf_tf]\n",
    "    ]\n",
    "\n",
    "for (test_vec, test_tf) in test_vecs:\n",
    "    print('stopwords:', test_vec.stop_words, ', tokenizer:', test_vec.tokenizer)\n",
    "    print('----------')\n",
    "    for line in get_matches(test_vec, test_tf, 2, compare_string):\n",
    "        print(line['text'])\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
